#!/bin/bash

#
# Name:             getip
# Description:      Script to retrieve an external IPv4 address from IP providing web sites.
# Requirements:     UNIX/Linux, Bash, either curl or wget.
# Usage:            getip [-g | -c | -u url] [-n num_sources] [-t timeout_secs] [-b] [-v] [-h]
# Exit Status:      0 on success, and non-zero on failure.
# Author:           mattst@i-dig.info
# Version:
# Homepage:         https://github.com/mattst/getip
# License:          GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html
#
#
# The complete list of all utilities and Bash shell commands used by the getip script:
#
# awk, bc, cat, curl, date, disown, echo, exit, getopts, grep, hash, kill, man, mktemp, printf, ps,
# $RANDOM, read, rm, sed, shift, sort, tr, uniq, unset, wc, wget. [Either wget or curl required.]
#
# With the exception of wget and curl all of the above utilities and commands are expected to exist
# on all modern UNIX like operating systems. If neither wget nor curl are installed the script will
# advise the user to install one of them.
#
#
# Description:
#
# getip is a script used to retrieve a wide area network (WAN) IPv4 address from behind a router
# using web pages which provide the IP address in plain text or HTML. Note: IPv4 only, not IPv6.
#
# getip echoes the IP address so that it is displayed in the shell or so that it can be stored in a
# variable if getip is called from within another script.
#
# Command line options (all optional, in typical use none are necessary.):
#
# -g           GET; get the IP from multiple sources and verify they are all the same (default).
# -c           CHECK; display the IP address returned by all the web sources and show stats.
# -u url       TEST; test an URL for possible inclusion in the source urls and show info.
# -n number    Set the NUMBER of sources to use for verification. Range >=2 and <=5 (default 2).
# -t seconds   Set the TIMEOUT for each source. Real numbers are permitted (e.g. '1.5', '0.75').
# -b           BARE output; display only the IP address and not the "IPv4 address:" prefix.
# -v           VERBOSE; output information while the script is running.
# -h, --help   HELP; output program usage and help.
# --version    Display the VERSION of the script.
#
# GET is the default operation so -g is not needed on the command line, is uses the default number
# of sources which is 2 unless '-n number' is used to set the number of sources.
#
#
# The getip script uses a file containing a long list of web pages, each of which provide the IP
# address in either plain text or HTML, this is known as the sources list. Each web page url is on a
# separate line in the file. The sources list is stored online on the script's github page. Each
# time the script is run it downloads the sources list - by doing this the script always uses the
# most up-to-date version of the list, rather than a local copy which would soon contain sites that
# no longer exist, have become slow to respond, or which are otherwise no longer reliable.
#
# From time to time a web page used as a source will stop providing IP addresses, either temporarily
# or permanently, but an example IP address might remain on the page, or an IP-like software version
# number might be present on the page (embedded within the HTML) and which could be mistaken for a
# real IP address (although the script tries hard to spot and ignore these). In such circumstances
# an IP address fetching script could provide a user with an incorrect IP address. The getip script
# makes sure this does not happen.
#
# The getip script retrieves the IP address from multiple sources and checks that they have supplied
# the same IP address. The default number of sources used is 2 but this can be set on the command
# line using the -n option, the range of values is >=2 and <=5. The default is considered to be
# sufficient due to the unlikelihood of 2 sources both providing the same incorrect IP address. Very
# cautious users might want to use 3 sources, while 5 would indicate paranoia. Clearly the more
# sources used the longer it takes [guesstimate about 1 second per source on average].
#
#
# Description of Options:
# FAST                   - Command line switch: -f
#
# In fast mode getip will retrieve the IP address from just one source with no verification. It is
# generally faster, though not guaranteed to be. It is suggested that fast mode only be used when a
# user already knows their IP address and is seeking confirmation of it, for instance if checking
# whether a connection to a VPN has finished or succeeded. Fast mode should never be used when
# calling getip from within another script.
#
#
# CHECK                  - Command line switch: -c
#
# In check mode getip will display a table in the shell of all the web sources, the IP address which
# was retrieved from the source, or a message of failure, and the time taken to retrieve the IP
# address. In addition it displays some statistics at the end. It can be used by users to check that
# all the sources are functioning correctly. getip will continue to function perfectly adequately
# with even 25% of the sources down. If more than 15% are down you may wish to download the latest
# version of the script or manually delete sources which aren't working from the list below.
#
#
# TESTURL                - Command line switch: -u url
#
# In test url mode getip will test the url to see if it is suitable for adding to the source list.
# getip will display a small table showing the url's status; whether the Url successfully returned a
# single valid IP address, or failed by supplying more than one valid IP address, no IP address at
# all, or if the timeout was exceeded. Only experienced users should use this feature to add an url
# to the source list. If you do use this to find a new url that is suitable for inclusion please
# contact the developer with the url.
#
#
# The other command line options:
#
# NUMBER OF SOURCES      - Command line switch: -n num_sources [Default 2, range: >=2 and <=5.]
#
# Sets the number of sources to use in the multi operation mode.
#
#
# TIMEOUT, FOR EACH SOURCE   - Command line switch: -t seconds
#                            - Range >=0.2 and <=30. [Real numbers are permitted.]
#                            - Default timeout in multi mode:    1.0
#                            - Default timeout in fast mode:     0.75
#                            - Default timeout in check mode:    10.0
#                            - Default timeout in test url mode: 10.0
#
# Sets the timeout in seconds for each source, not an overall timeout for the script. When a source
# gives no response or is slow to respond, getip simply moves on to the next source in the sources
# list. Each of the operation modes has its own default timeout (shown above). The allowed range is
# large, >=0.2 and <=30, as large variations in speed of web access and the user's physical location
# both mean a flexible timeout is sensible, however values less than 0.75 or greater than 3 are not
# usually advisable in multi or fast mode. In check and test url modes a high timeout facilitates
# checking whether sources are functioning at all or not.
#
# There is no 'global' timeout feature for getip, however the timeout multiplied by the number of
# sources means there is a de facto 'global' timeout.
#
#
# BARE                   - Command line switch: -b
#
# Turn bare output on - the script will display only the IP address and not the "IPv4 address:"
# prefix.
#
#
# VERBOSE                - Command line switch: -v
#
# Turns verbose on - the script will output diagnostic information while it runs.
#
#
# HELP                   - Command line switch: -h or --help
#
# Outputs program usage and help then exits.
#


##
## START OF SCRIPT.
##

#
# The Principal Variables.
#

# Holds the script version number.
version="0.9c"

# Holds the url of the list of source urls.
sourceUrlsListUrl="https://crius.feralhosting.com/gencon/SourceUrlsList"

# Holds the minimum number of source urls that are required.
sourceUrlsMinimum="15"

# Array which holds the urls from $sourceUrlsListUrl - the array is populated below.
urlArray=""

# The number of urls in $urlArray, set below.
urlArrayLength="0"

# $operationMode holds the operation mode, default 'GETIP'.
# Possible values: 'GETIP', 'CHECK', or 'TESTURL'.
operationMode="GETIP"

# Sets the default number of sources to use in GETIP mode. Recommended: 2 (Range: 2-5).
numIpToUseForGetIP="2"

# Set the default timeout in seconds for the retrieval of each source. A different default timeout
# can be set for each mode. Timeouts may be fractions of a second, e.g. 1.5, 0.75, .75

# The timeout variable will be set to the appropriate value later.
timeout="0"

# GETIP mode: keep the timeout low so that if a source is offline or slow to respond the script
# can move on to the next source. Recommended: 0.75 to 3.0.
timeoutGetIPMode="1.5"

# CHECK mode: set the timeout high to give the url a chance to succeed. Recommended: 10.
timeoutCheckMode="10"

# TESTURL mode: set the timeout high to give the url a chance to succeed. Recommended: 10.
timeoutTestUrlMode="10"

# Web url of source to test in TESTURL mode.
testUrlAddress=""

# Variable to hold the default download program (which to use if both wget and curl are installed).
# Possible values: 'WGET', or 'CURL'.
urlDefaultDownloadProgram="WGET"

# Variable to hold if the user has set the download program (the -d option).
userSetUrlDownloadProgram="FALSE"

# Variable to hold if the user has set the number of source IPs to use (the -n option).
userSetNumIpToUseForGetIP="FALSE"

# Variable to hold if the user has set a timeout (the -t option).
userSetTimeout="FALSE"

# Variable to hold if the user has set the bare output option (the -b option).
bareOutput="FALSE"

# Variable to hold if the user has turned on verbose reporting (the -v option).
verbose="FALSE"

# Counter to count how many modes the user set on the command line. Since only 1 mode can be set
# this facilitates checking the user has not inadvertently set more than 1 mode.
userSetModesCounter="0"

# Set the user agent to use for web page downloads. The script does not try to hide that it is a
# script. The user agent header is modelled on the one used by Google's 'googlebot':
# Googlebot 2.1: "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"
userAgent="Mozilla/5.0 (compatible; getipscript/$version; +https://github.com/mattst/getip)"

# Constants to hold the values returned by the Get_Ip_From_Url() function.
GetIpSingleValidIP="0"
GetIpNoValidIP="1"
GetIpMultipleValidIP="2"
GetIpTimedOut="3"
GetIpTempFileCreationFailed="4"

# Constants to hold the values returned by the Verify_IP_List() function.
VerifyIpAllTheSame="0"
VerifyIpNotTheSame="1"

# Variables used for stats in the check operation mode.
statsValidIpAddressList=""
statsTimesList=""
statsTotalValidIp="0"
statsTotalInValidIp="0"

# Constants to hold the various exit statuses of the script.
# Careful using ST's InsertNums here, success must be 0 not 1.
ExitStatusSuccess="0"
ExitStatusErrorUrlArgInvalid="101"
ExitStatusErrorNumSourcesArgInvalid="102"
ExitStatusErrorTimeoutArgInvalid="103"
ExitStatusErrorUrlDownloadProgramArgInvalid="104"
ExitStatusErrorOptionInvalid="105"
ExitStatusErrorArgMissing="106"
ExitStatusErrorUserSetMoreThanOneMode="107"
ExitStatusErrorUserSetVerboseAndBare="108"
ExitStatusErrorUrlDownloadProgramNotInstalled="109"
ExitStatusErrorDownloadWebSourceListFailed="110"
ExitStatusErrorNotEnoughSourceUrls="111"
ExitStatusErrorTempFileCreationFailed="112"
ExitStatusErrorFailedToGetIPAddress="113"
ExitStatusErrorCheckModeAllUrlsFailed="114"


#
# The Functions.
#


# Function to display help.
Display_Usage_Message()
{
    # Create a temp file to store the man page here document.
    # Don't use 'local' or $? won't work.
    tempFileNameForGetIpManPage=$(mktemp -q -t "getip.tmp.XXXXXX")
    mktempFileCreationRetVal=$?

    if [ "$mktempFileCreationRetVal" -ne "0" ]; then
        Output_Error_Message "TempFileCreationFailed"
        exit "$ExitStatusErrorTempFileCreationFailed"
    fi

# Output a here document of the getip man page to $tempFileNameForGetIpManPage.
# Here documents don't work well with indentation, keep to the hard left.
cat >>$tempFileNameForGetIpManPage <<EOF

.TH GETIP 1 "29 Sep 2015" "1.0" "GETIP VERSION 1.0"

.SH NAME

getip \- retrieves the WAN IP address

.SH SYNOPSIS

getip [-m | -f | -c | -u url] [-n num_sources] [-t timeout_secs] [-v] [-h]

.SH REQUIREMENTS

The BASH shell and either wget or curl must be installed. Most modern UNIX like systems come with BASH and wget pre-installed. wget and curl are both programs which download pages from the web. getip works equally well with them both. wget is used by default if both are installed on the system.

.SH DESCRIPTION

getip is a BASH script used to retrieve the WAN IP address from behind a router using web sites (sources) which provide the IP address in plain text or HTML.

From time to time a web page used as a source will stop providing IP addresses, either temporarily or permanently, but an example IP address might remain on the page, or an IP-like software version number might be present, embedded in the HTML, and which could be mistaken for a real IP address (although the script tries hard to spot version numbers so they can be ignored). In such cases an IP address fetching script could provide a user with an incorrect IP address. getip uses multi mode by default to prevent this from happening.

In multi mode the IP address is retrieved from multiple sources (default: 2) and compared, so that the correct IP address can be provided. Users are advised to use multi mode in preference to fast mode.

The getip script retrieves IPv4 addresses only and not IPv6 addresses.

This script currently contains over 100 web sources.

The list of web sources is randomized every time the script is run. This is so that undue pressure is not placed on servers near the top of the list. The randomizing process is done very quickly and does not have a significant impact on the running time of the script.

.SH OPTIONS
.BR
In typical usage no options are necessary.
.BR

.TP
\fB\-m\fR
Multi mode (default); fetch the IP address from multiple sources and check that they are all the same. In multi mode the default number of sources to use is 2. This is the default mode so \fB\-m\fR is optional. See: \fB\-n\fR \fBnum_sources\fR

.TP
\fB\-f\fR
Fast mode; fetch the IP address from just one source in order to retrieve it more quickly than in multi mode. Fast mode is not guaranteed to be faster than multi mode but on average it will be slightly faster. It is advisable that users only use fast mode to confirm their IP address when it is already known, e.g. checking a VPN connection. In some circumstances an incorrect IP address can be returned in fast mode, see \fBDescription\fR section above.

.TP
\fB\-c\fR
Check mode; displays a table containing the url of each source, the IP address that it returned (or a failure message), the time taken to retrieve the IP address, and various statistics. Used to test the sources list.

.TP
\fB\-u\fR \fBurl\fR
Test Url mode; tests an url for inclusion in the sources list. It will display whether the url returned a single IP address (which is required for inclusion in the sources list), multiple IP addresses, or no IP addresses at all. To aid debugging it will list all IP addresses returned.

.TP
\fB\-n\fR \fBnum_sources\fR
Sets the Number of sources to use in multi mode. The allowed range of values is >=2 and <=5. The default value is 2.

.TP
\fB\-t\fR \fBnum_seconds\fR
Sets the Timeout for each source. This is not an overall timeout for the script. When a source gives no response or is slow to respond, getip moves on to the next source and this is the timeout in seconds for each one. Note: Real numbers are permitted, e.g. 0.75, 1.5, .85, etc. The allowed range of values is >=0.2 and <=30 (but these extremes are overkill).

The default timeouts are dependant on mode, in seconds they are; multi mode 1, fast mode 0.75, check mode 10, test url mode 10.

.TP
\fB\-b\fR
Bare output; display only the IP address and not the "IPv4 address:" prefix.

.TP
\fB\-v\fR
Verbose; display detailed information while the script runs.

.TP
\fB\-h\fR, \fB\-\-help\fR
Help; display usage and help.

.TP
\fB\-\-version\fR
Display version number.

.SH EXIT STATUS
getip returns 0 on success, and non-zero on failure.

.SH BUGS
No known bugs.

.SH HOMEPAGE
https://github.com/mattst/getip
.LP
Feel free to submit new IP address providing web pages to be added to the sources list.

.SH AUTHOR
<mattst@i-dig.info>
EOF

    # Display the man page.
    man "$tempFileNameForGetIpManPage"

    # Delete the temp file.
    if [ -f "$tempFileNameForGetIpManPage" ]; then rm "$tempFileNameForGetIpManPage"; fi
}


# Function to send the various error messages to STDERR.
Output_Error_Message()
{
    # Assign $errToDisplay the value of the 1st function arg (NOT script arg).
    local errToDisplay=$1

    # Assign $additionalInfo the value of the 2nd function arg (NOT script arg).
    # Some errors display a configurable piece of information, e.g. an option.
    local additionalInfo=$2

    # Output the appropriate error message to STDERR.

    echo "" >&2

    if [ "$errToDisplay" = "ArgInvalid" ]; then
        echo "The argument given to the $additionalInfo option is invalid." >&2

    elif [ "$errToDisplay" = "OptionInvalid" ]; then
        echo "An invalid option has been entered." >&2

    elif [ "$errToDisplay" = "ArgMissing" ]; then
        echo "The argument is missing for the option: -$additionalInfo" >&2

    elif [ "$errToDisplay" = "UserSetMoreThanOneMode" ]; then
        echo "Only one operation mode can be used at a time." >&2

    elif [ "$errToDisplay" = "UserSetVerboseAndBare" ]; then
        echo "Verbose and bare output can not be used at the same time." >&2

    elif [ "$errToDisplay" = "TempFileCreationFailed" ]; then
        echo "Unable to create a temp file using 'mktemp'." >&2

    elif [ "$errToDisplay" = "DownloadWebSourceListFailed" ]; then
        echo "Unable to download the list of web sources from:" >&2
        echo "$sourceUrlsListUrl" >&2

    elif [ "$errToDisplay" = "NotEnoughSourceUrls" ]; then
        echo "Not enough web sources urls, the minimum required is $sourceUrlsMinimum." >&2

    elif [ "$errToDisplay" = "FailedToGetIPAddress" ]; then
        echo "The script failed to get the IP address." >&2

    elif [ "$errToDisplay" = "WgetNotInstalled" ]; then
        echo "The program wget is not installed on your system." >&2

    elif [ "$errToDisplay" = "CurlNotInstalled" ]; then
        echo "The program curl is not installed on your system." >&2

    elif [ "$errToDisplay" = "WgetAndCurlNotInstalled" ]; then
        echo "The getip script requires either 'wget' or 'curl' to access the web, please" >&2
        echo "install one of them in order to use this script. wget and curl are both" >&2
        echo "programs that can retrieve web pages, and they are widely available for all" >&2
        echo "UNIX/Linux based systems. The getip script works equally well with either." >&2
    fi

    echo "" >&2
    echo "Use \"getip -h\" for usage and help." >&2
}


# Function to fetch the web sources list and store the urls in the $urlArray array.
Read_Source_Url_List()
{
    # Create a temp file to store the online source url list file in.
    # Don't use 'local' or $? won't work.
    tempFileNameForSourceUrls=$(mktemp -q -t "getip.tmp.XXXXXX")
    mktempFileCreationRetVal=$?

    if [ "$mktempFileCreationRetVal" -ne "0" ]; then
        Output_Error_Message "TempFileCreationFailed"
        exit "$ExitStatusErrorTempFileCreationFailed"
    fi

    # Use wget to download the source url list file.
    if [ "$urlDownloadProgram" = "WGET" ]; then

        wget --quiet --tries=1 --user-agent="$userAgent" --output-document=- \
             "$sourceUrlsListUrl" > "$tempFileNameForSourceUrls"
        wgetDownloadSourceUrlsListRetVal=$?

        if [ "$wgetDownloadSourceUrlsListRetVal" -ne "0" ]; then
            Output_Error_Message "DownloadWebSourceListFailed"
            exit "$ExitStatusErrorDownloadWebSourceListFailed"
        fi

    # Use curl to download the source url list file.
    elif [ "$urlDownloadProgram" = "CURL" ]; then

        curl --silent --user-agent "$userAgent" "$sourceUrlsListUrl" > "$tempFileNameForSourceUrls"
        curlDownloadSourceUrlsListRetVal=$?

        if [ "$curlDownloadSourceUrlsListRetVal" -ne "0" ]; then
            Output_Error_Message "DownloadWebSourceListFailed"
            exit "$ExitStatusErrorDownloadWebSourceListFailed"
        fi
    fi

    # Read the urls from $tempFileNameForSourceUrls into the $urlArray.
    # The urlArray must be INDEXED IN NUMERICAL SEQUENCE FROM 0.

    urlIndex="0"

    while read -r line ; do

        # Store only lines which are urls by seeing if the first 4 chars are 'http'.
        lineFirst4Chars=${line:0:4}
        lineFirst4CharsLC=$(echo "$lineFirst4Chars" | tr '[:upper:]' '[:lower:]')

        if [ "$lineFirst4CharsLC" = "http" ]; then
            urlArray[$urlIndex]="$line"
            let 'urlIndex = urlIndex + 1'
        fi

    done < "$tempFileNameForSourceUrls"

    # Set the length of the urlArray array.
    urlArrayLength="$urlIndex"

    # Delete the temp file.
    if [ -f "$tempFileNameForSourceUrls" ]; then rm "$tempFileNameForSourceUrls"; fi
}


# Function that randomizes the $urlArray array. Since this script is being publicly released it is
# sensible to randomize the sources so as not to place undue pressure on the servers at the top of
# the list. This is an implementation of the Knuth shuffle algorithm (aka Fisher-Yates shuffle),
# which is a very efficient randomizer, needing just one pass through an array.
# IMPORTANT: THE $urlArray ARRAY MUST BE INDEXED IN NUMERICAL SEQUENCE FROM 0 FOR THIS FUNCTION.
Randomize_Url_List()
{
    # Bash $RANDOM provides a random number in the range 0..32767 so 32768 possible values.
    local randMax="32768"

    # Start at the number of items in the array (i.e. final element's index + 1).
    local index="$urlArrayLength"

    # Loop down through the array randomly swapping the current element with another randomly
    # chosen element (possibly itself). The use of >1 needs a moment to understand... if instead
    # it was >0 then the final iteration would always swap index 0 with itself.

    while [ "$index" -gt "1" ]; do

        # Modulo bias avoidance as per Knuth shuffle algorithm description. Calculate the highest
        # usable random number so that the modulo by index calculation will not result in any modulo
        # bias. Note: Not really necessary but the function only takes ~0.003 seconds with 100 urls
        # (on my PC) so why not do it right!? That's just ~0.15% of the approx. average run time.

        # Integer arithmetic, the division will be rounded down.
        let "highestUsableRandNum = (($randMax / $index) * $index) - 1"

        # Get a random number within the modulo bias avoidance range.
        local randNum="$RANDOM"
        while [ "$randNum" -gt "$highestUsableRandNum" ]; do
            randNum="$RANDOM"
        done

        # Get a random index in the range 0..index-1.
        let "randIndex = randNum % index"

        # Decrement index to reference the current 'last' element in the array. For the first loop
        # iteration index will be $urlArrayLength - 1 (the final element of the array) and for the
        # last loop iteration index will be 1. By doing so the current index will be swapped with
        # a randomly chosen index ($randIndex) in the range 0..index, so elements will sometimes
        # be 'swapped' with themselves (if elements could not stay put it wouldn't be random).

        let "index = index - 1"
        local tempUrl=${urlArray[$index]}
        urlArray[$index]=${urlArray[$randIndex]}
        urlArray[$randIndex]=$tempUrl

    done
}


# Function to extract valid IP addresses from the file path given in the 1st function arg. As
# output it echos a list of valid IP addresses seperated by newlines for capture in a variable
# at the point of function invocation.
Extract_Ip_Addresses_From_File()
{
    # Assign $urlSourceFileName the value of the 1st function arg (NOT script arg).
    local urlSourceFileName="$1"

    # The following Awk program will search for and print all valid IP addresses in the file
    # which is given to it as input.

    # The regex ipLikeSequence deliberately matches IP address like sequences which are too long
    # to be a valid IP so that the regex does not examine something like '11.22.33.44.55' and
    # match just the '11.22.33.44' section of it, and in so doing cause something that is
    # definitely not an IP address to get mistaken for a valid one. IP address like sequences
    # are checked in the END section to make sure they have exactly 4 segments, separated by
    # dots (".") and that each of the 4 numbers are within the 0..255 range of a valid IP.

    # The regex digitSequenceTooLongNotIP will match sequences of numbers which are longer than
    # 3 digits. They are all removed as they can not possibly be part of an IP address.

    # The regex versioningNotIP attempts to spot version numbers which happen to be in the same
    # format as an IP address (which they are often are). e.g. Version 1.2.0.12
    # Any ipLikeSequence which follows words like "Version", "Ver", or "V", will be removed.

    # Version numbers are also often embedded in an url like "1.2.3.4" in these examples:
    # e.g. <script language="JavaScript" src="http://web.com/libs/1.2.3.4/file.js"></script>
    # e.g. <script language="JavaScript" src="http://web.com/libs/v.1.2.3.4/file.js"></script>
    # The regexes beginsWithFwdSlashNotIP and endsWithFwdSlashNotIP match an ipLikeSequence which
    # begins or ends with a forward slash so that those sequences can be removed.

    local awkExtractIPAddresses='
    BEGIN {
        # Regex to match an IP address like sequence (even if too long to be an IP). This is
        # deliberately a loose match, the END section will check for IP address validity.
        ipLikeSequence = "[0-9]+[.][0-9]+[.][0-9]+[.][0-9]+[0-9.]*";

        # Regex to match a number sequence longer than 3 digits.
        digitSequenceTooLongNotIP = "[0-9][0-9][0-9][0-9]+";

        # Regex to match an IP address like sequence which is a version number.
        # Equivalent to "(version|ver|v)[ .:]*" in conjunction with: line = tolower($0);
        versioningNotIP = "[Vv]([Ee][Rr]([Ss][Ii][Oo][Nn])?)?[ .:]*" ipLikeSequence;

        # Regexes to match IP address like sequences next to forward slashes, to avoid version
        # numbers in urls: e.g. http://web.com/libs/1.2.3.4/file.js
        beginsWithFwdSlashNotIP = "[/]" ipLikeSequence;
        endsWithFwdSlashNotIP = ipLikeSequence "[/]";
    }
    {
        # Set line to the current line (more efficient than using $0 below).
        line = $0;

        # Replace sequences on line which will interfere with extracting genuine IPs. Use a
        # replacement char and not the empty string to avoid accidentally creating a valid IP
        # address from digits on either side of the removed sections. Use "/" as the replacement
        # char for the 2 "FwdSlash" regexes so that multiple number dot slash sequences all get
        # removed, as using "x" could result in inadvertently leaving such a sequence in place.
        # e.g. "/lib1.2.3.4/5.6.7.8/9.10.11.12/file.js" would leave "/lib1.2.3.4xx/file.js".

        gsub(digitSequenceTooLongNotIP, "x", line);
        gsub(versioningNotIP, "x", line);
        gsub(beginsWithFwdSlashNotIP, "/", line);
        gsub(endsWithFwdSlashNotIP, "/", line);

        # Loop through the current line matching IP address like sequences and storing them in
        # the INDEX of the array ipUniqueMatches. By using ipMatch as the array index duplicates
        # are avoided and the values can be easily retrieved by the for loop in the END section.
        # match() automatically sets the built in variables RSTART and RLENGTH.

        while (match(line, ipLikeSequence))
        {
            ipMatch = substr(line, RSTART, RLENGTH);
            ipUniqueMatches[ipMatch];
            line = substr(line, RSTART + RLENGTH + 1);
        }
    }
    END {
        # Define some IP address related constants.
        ipRangeMin = 0;
        ipRangeMax = 255;
        ipNumSegments = 4;
        ipDelimiter = ".";

        # Loop through the ipUniqueMatches array and print any valid IP addresses. The awk "for
        # each" type of loop is different from the norm. It provides the indexes of the array
        # and NOT the values of the array elements which is more usual in this type of loop.

        for (ipMatch in ipUniqueMatches)
        {
            numSegments = split(ipMatch, ipSegments, ipDelimiter);
            if (numSegments == ipNumSegments &&
                ipSegments[1] >= ipRangeMin && ipSegments[1] <= ipRangeMax &&
                ipSegments[2] >= ipRangeMin && ipSegments[2] <= ipRangeMax &&
                ipSegments[3] >= ipRangeMin && ipSegments[3] <= ipRangeMax &&
                ipSegments[4] >= ipRangeMin && ipSegments[4] <= ipRangeMax)
            {
                print ipMatch;
            }
        }
    }'

    # Extract valid IP addresses from $urlSourceFileName, each will be separated by a new line.
    local awkValidIpAddresses=$(awk "$awkExtractIPAddresses" < "$urlSourceFileName")

    # Echo $awkValidIpAddresses for capture in a variable at the point of function invocation.
    echo "$awkValidIpAddresses"
}


# Function that retrieves the source's content and returns all unique IP addresses in it. The
# function provides an accurate timeout facility; neither curl nor wget reliably honour any timeout
# value which has been set nor do they allow timeouts in fractions of a second. Since getip uses
# many different sources a low timeout is used, if one source fails to return very quickly then the
# next source is tried. With this methodology a reliable and accurate timeout is required, this
# function provides it.
Get_Ip_From_Url()
{
    # Assign $urlToDownload the value of the 1st function arg (NOT script arg).
    local urlToDownload="$1"

    # Create a temp file to store the page source of $urlToDownload.
    # Don't use 'local' or $? won't work.
    tempFileNameForGetIp=$(mktemp -q -t "getip.tmp.XXXXXX")
    mktempFileCreationRetVal=$?

    # If there is a temp file creation error return $GetIpTempFileCreationFailed. The function is
    # called using the $() construct which means a subshell will be created for it and any exit
    # call in the function will exit only the subshell and not the script.
    if [ "$mktempFileCreationRetVal" -ne "0" ]; then
        return "$GetIpTempFileCreationFailed"
    fi

    # Download the url and store its contents in the temp file. The process is forked to facilitate
    # the timeout procedure. The use of disown, which removes a job from the shell's active jobs
    # table, is so that if the process is later killed (which it will be if it times out) then
    # no shell message is displayed.

    # Store the start time for the timeout. Note: %s seconds, %N nanoseconds.
    local timeoutStart=$(date +%s.%N)

    # Use wget to download the url.
    if [ "$urlDownloadProgram" = "WGET" ]; then

        wget --quiet --tries=1 --user-agent="$userAgent" --output-document=- \
             "$urlToDownload" > "$tempFileNameForGetIp" &

        urlDownloadProcessId=$!
    fi

    # Use curl to download the url.
    if [ "$urlDownloadProgram" = "CURL" ]; then

        curl --silent --user-agent "$userAgent" "$urlToDownload" > "$tempFileNameForGetIp" &

        urlDownloadProcessId=$!
    fi

    # For some reason even if kill has both stdout and stderr redirected to /dev/null the death of
    # the process is still output, using disown to remove the job from the shell's active jobs
    # table stops this from happening so there are no unsightly terminal messages.
    disown "$urlDownloadProcessId"

    # The following loop handles the timeout procedure for the url download process. ps is used to
    # see if the download process is still alive. The loop will finish when the process has
    # completed or when the timeout is exceeded.

    local isUrlDownloadDone="FALSE"
    local isUrlDownloadTimedOut="FALSE"

    while [ "$isUrlDownloadDone" = "FALSE" -a "$isUrlDownloadTimedOut" = "FALSE" ]; do

        # Store whether the url download process is still listed by ps.
        ps -e | grep --quiet "$urlDownloadProcessId"
        local processGrepRetVal=$?

        # If the url download process has finished.
        if [ "$processGrepRetVal" -ne "0" ]; then
            isUrlDownloadDone="TRUE"

        # If the url download process has not finished.
        else
            # Store the current time for the timeout. Note: %s seconds, %N nanoseconds.
            local timeoutNow=$(date +%s.%N)

            # Use bc to check if the timeout has been exceeded.
            local bcExpTimeout="if (($timeoutNow - $timeoutStart) > $timeout) 1 else 0"
            local bcExpTimeoutRetVal=$(echo "$bcExpTimeout" | bc -l)

            # The timeout has been exceeded.
            if [ "$bcExpTimeoutRetVal" -eq "1" ]; then
                isUrlDownloadTimedOut="TRUE"
            fi
        fi
    done

    # If the url download process completed successfully.
    if [ "$isUrlDownloadDone" = "TRUE" ]; then

        # Use the function Extract_Ip_Addresses_From_File() to extract valid IP addresses from
        # $tempFileNameForGetIp. Each IP address will be separated by a new line but if the source
        # is working as expected then there will be exactly one IP address.
        local ipAddressList=$(Extract_Ip_Addresses_From_File "$tempFileNameForGetIp")

        # Delete the temp file.
        if [ -f "$tempFileNameForGetIp" ]; then rm "$tempFileNameForGetIp"; fi

        # Array to hold the IP address or addresses and an associated counter.
        local ipAddressValidArray=""
        local ipAddressValidCounter="0"

        # Iterate through $ipAddressList storing the IP address(es) in the array.
        for validIpAddress in $(echo "$ipAddressList" | tr "\n" " "); do
            ipAddressValidArray[$ipAddressValidCounter]="$validIpAddress"
            let "ipAddressValidCounter = ipAddressValidCounter + 1"
        done

        # If the length of the array is exactly 1 then that is considered to be the user's IP
        # address, it is echoed so that it can be placed in a variable at the point of function
        # invocation, and the constant $GetIpSingleValidIP is returned - success.
        if [ "$ipAddressValidCounter" -eq "1" ]; then
            echo "${ipAddressValidArray[0]}"
            return "$GetIpSingleValidIP"

        # If the array has no members then the constant $GetIpNoValidIP is returned, no valid
        # IP address was found - failure.
        elif [ "$ipAddressValidCounter" -lt "1" ]; then
            return "$GetIpNoValidIP"

        # If the length of the array is more than 1 then the constant $GetIpMultipleValidIP is
        # returned, more than one unique and valid IP address was found, there is no way to tell
        # which of them is the user's IP address - failure.
        elif [ "$ipAddressValidCounter" -gt "1" ]; then
            # If in test url mode then echo all the valid IP addresses that were found.
            if [ "$operationMode" = "TESTURL" ]; then echo "$ipAddressList"; fi
            return "$GetIpMultipleValidIP"
        fi
    fi

    # If the url download process timed out (which it must have done or this section of the
    # function would not have been reached) then kill the process (and make doubly sure).

    # Since the process being killed has been disowned (removed from the shell's active jobs
    # table) the redirect of stdout and stderr to /dev/null may be unnecessary to hide the kill
    # messages, it is not necessary on the 3 Linux systems used to test the script, other OSes?

    if [ "$isUrlDownloadTimedOut" = "TRUE" ]; then

        kill -INT "$urlDownloadProcessId" > /dev/null 2>&1
        local killRetVal=$?

        if [ "$killRetVal" -ne "0" ]; then
            kill -KILL "$urlDownloadProcessId" > /dev/null 2>&1
        fi
    fi

    # Delete the temp file.
    if [ -f "$tempFileNameForGetIp" ]; then rm "$tempFileNameForGetIp"; fi

    # The download process timed out.
    return "$GetIpTimedOut"
}


# Function to check that all the IP addresses passed to it are exactly the same.
Verify_IP_List()
{
    # Assign all the IP addresses passed to this function to the array $ips.
    local ips=("$@")

    # Iterate through the array checking that all the IP addresses are the same.

    for ip in "${ips[@]}"; do

        # If $ip is not the same as the first IP address in the array.
        if [ "$ip" != "${ips[0]}" ]; then
            return "$VerifyIpNotTheSame"
        fi
    done

    # All the IP addresses in the array must be the same.
    return "$VerifyIpAllTheSame"
}


# Function that adds information to the statistics variables (check mode only).
Add_To_Stats()
{
    # Assign the IP address, its validity, and retrieval time to local variables.
    local ipAddressForStats="$1"
    local ipStatusForStats="$2"
    local timeTakenForStats="$3"

    # If the IP address is valid.
    if [ "$ipStatusForStats" = "VALID_IP" ]; then

        # Add the IP address to the list of valid IP addresses. [The trailing space is essential.]
        statsValidIpAddressList+="$ipAddressForStats "

        # Add the time taken to the list of times taken. [The trailing space is essential.]
        statsTimesList+="$timeTakenForStats "

        # Increment the valid IP address counter.
        let "statsTotalValidIp = statsTotalValidIp + 1"

    # If the IP address is not valid increment the invalid IP address counter.
    else
        let "statsTotalInValidIp = statsTotalInValidIp + 1"
    fi
}


# Function to find the fastest time from the times in the $statsTimesList list (check mode only).
Find_Fastest_Time()
{
    # Awk expression to find the fastest time.
    local awkFastest='{ if (NR == 1) fastest = $1; if ($1 < fastest) fastest = $1; } \
                        END { printf("%.3f", fastest) }'

    # Pipe the $statsTimesList to awk to get the fastest time.
    local fastest=$(echo "$statsTimesList" | tr " " "\n" | awk "$awkFastest" )

    # Echo $fastest for capture at point of function invocation.
    echo "$fastest"
}


# Function to find the slowest time from the times in the $statsTimesList list (check mode only).
Find_Slowest_Time()
{
    # Awk expression to find the slowest time.
    local awkSlowest='{ if (NR == 1) slowest = $1; if ($1 > slowest) slowest = $1; } \
                        END { printf("%.3f", slowest) }'

    # Pipe the $statsTimesList to awk to get the slowest time.
    local slowest=$(echo "$statsTimesList" | tr " " "\n" | awk "$awkSlowest" )

    # Echo $slowest for capture at point of function invocation.
    echo "$slowest"
}


# Function to calculate the mean of the times in the $statsTimesList list (check mode only).
Calculate_Mean_Average_Time()
{
    # Awk expression to calculate the mean average.
    local awkMean='{ total += $1; num += 1; } \
                     END { mean = total / num; printf("%.3f", mean) }'

    # Pipe the $statsTimesList to awk to get the mean.
    local mean=$(echo "$statsTimesList" | tr " " "\n" | awk "$awkMean")

    # Echo $mean for capture at point of function invocation.
    echo "$mean"
}


# Function to calculate the median of the times in the $statsTimesList list (check mode only).
Calculate_Median_Average_Time()
{
    # Establish if there are an even or odd number of items stored in $statsTimesList.
    local medianItemsEvenOrOdd=""
    let 'modTwoOfTotalValidIp = statsTotalValidIp % 2'

    if [ "$modTwoOfTotalValidIp" = "0" ]; then medianItemsEvenOrOdd="EVEN"
    else                                       medianItemsEvenOrOdd="ODD"
    fi

    # If an odd number of items, the median is the middle item in the ordered list.
    if [ "$medianItemsEvenOrOdd" = "ODD" ]; then

        # Work out which is the middle item (integer arithmetic so division will be rounded down).
        local middleItem=""
        let "middleItem = (statsTotalValidIp / 2) + 1"

        # Awk expression to print the middle row which will be the median value.
        local awkMedianOdd='{ if (NR == midRow) printf("%.3f", $1) }'

        # Pipe the $statsTimesList to awk as a sorted list to get the median.
        local median=$(echo "$statsTimesList" | tr " " "\n" | sort -n |
                       awk "$awkMedianOdd" midRow="$middleItem")
    fi

    # If an even number of items, the median is the mean average of the 2 middle items.
    if [ "$medianItemsEvenOrOdd" = "EVEN" ]; then

        # Work out which are the 2 middle items.
        local middleItem1=""
        local middleItem2=""
        let "middleItem1 = statsTotalValidIp / 2"
        let "middleItem2 = middleItem1 + 1"

        # Awk expression to get the values of the 2 middle rows and then to work out and print
        # the median by calculating the mean average of the 2 middle rows.
        local awkMedianEven='{ if (NR == midRow1) med1 = $1; if (NR == midRow2) med2 = $1; } \
                             END { median = (med1 + med2) / 2; printf("%.3f", median) }'

        # Pipe the $statsTimesList to awk as a sorted list to get the median.
        local median=$(echo "$statsTimesList" | tr " " "\n" | sort -n |
                       awk "$awkMedianEven" midRow1="$middleItem1" midRow2="$middleItem2")
    fi

    # Echo $median for capture at point of function invocation.
    echo "$median"
}


# Function to display the statistical information (check mode only).
Display_Stats()
{
    # Trim whitespace from $statsTimesList and $statsValidIpAddressList.
    local sedExpTrim='s/^[ \t]*//g;s/[ \t]*$//g'
    statsTimesList=$(echo "$statsTimesList" | sed "$sedExpTrim")
    statsValidIpAddressList=$(echo "$statsValidIpAddressList" | sed "$sedExpTrim")

    # Find the fastest of the successful retrieval times.
    local timeFastest=$(Find_Fastest_Time)

    # Find the slowest of the successful retrieval times.
    local timeSlowest=$(Find_Slowest_Time)

    # Calculate the mean average of the successful retrieval times.
    local timeMean=$(Calculate_Mean_Average_Time)

    # Calculate the median average of the successful retrieval times.
    local timeMedian=$(Calculate_Median_Average_Time)

    # Calculate the percentages of successful and failed retrieval (2 decimal places).
    local bcExpPercentSuccess="($statsTotalValidIp / $urlArrayLength) * 100"
    local percentSuccess=$(printf "%.2f" $(echo "$bcExpPercentSuccess" | bc -l))
    local bcExpPercentFailed="100 - $percentSuccess"
    local percentFailed=$(printf "%.2f" $(echo "$bcExpPercentFailed" | bc -l))

    # Calculate the number of unique IP addresses held in $statsValidIpAddressList.
    # Use printf to avoid the new line that echo would add.
    local numUniqueIp=$(printf "$statsValidIpAddressList" | tr " " "\n" | sort -n | uniq | wc -l)

    # Output the statistics.

    printf "%s\n" "------------------------------------------------------------------------------"

    printf "%-62s %s\n" "Total Number Sites Checked:" "$urlArrayLength"

    printf "%-62s %-3s (%s%%)\n" "IP Addresses - Successfully Retrieved:" \
                                 "$statsTotalValidIp" "$percentSuccess"

    printf "%-62s %-3s (%s%%)\n" "IP Addresses - Failed (Timed Out / Invalid IP):" \
                                 "$statsTotalInValidIp" "$percentFailed"

    printf "%-62s %s\n" "Timeout For Each Url:" "$timeout secs"

    printf "%-62s %s\n" "Fastest IP Successful Retrieval:" "$timeFastest secs"

    printf "%-62s %s\n" "Slowest IP Successful Retrieval:" "$timeSlowest secs"

    printf "%-62s %s\n" "Mean Average IP Successful Retrieval:" "$timeMean secs"

    printf "%-62s %s\n" "Median Average IP Successful Retrieval:" "$timeMedian secs"

    # Issue a warning if not exactly 1 unique IP.
    if [ "$numUniqueIp" = "1" ]; then
        printf "%-62s %s\n" "Unique IP Addresses Retrieved (Should Be 1):" "$numUniqueIp"
    else
        printf "%-62s %s *WARNING*\n" "Unique IP Addresses Retrieved (Should Be 1):" "$numUniqueIp"
    fi

    printf "%s\n" "------------------------------------------------------------------------------"

    # Echo a warning if the number of unique IP addresses is > 1, and list them.
    if [ "$numUniqueIp" -gt "1" ]; then
        printf "\nWARNING: The number of unique IP addresses retrieved exceeds one, it should be\n"
        printf "exactly one, your IP address. One or more of the sources is no longer suitable\n"
        printf "for use by this script. If you have the time please contact the developer with\n"
        printf "the url of the problematic source, use the -h option for contact details.\n\n"

        # List each unique IP address in a table along with its number of occurrences.

        # This awk code uses a useful aspect of awk where any number or string in awk may be used
        # as an array index. In this case the IP addresses piped to awk will serve as the array
        # indexes for the countIP[] array.
        local awkExpIpCount='{ countIP[$1]++ } END { for (ip in countIP) \
                               printf("%-25s %d\n", ip, countIP[ip]); }'

        # printf "Unique IP Addresses List:\n\n"
        printf "Unique IP Addresses List:\n\n"
        # printf "%s\n\n" "-------------------------"
        printf "IP Address         Num Occurrences\n"
        printf "%s\n" "----------------------------------"
        echo "$statsValidIpAddressList" | tr " " "\n" | awk "$awkExpIpCount"
        printf "%s\n" "----------------------------------"
    fi
}


# Function which controls IP address retrieval and verification.
Handle_Get_IP_Mode()
{
    if [ "$verbose" = "TRUE" ]; then
        printf "\n%-27s %s\n" "Script Version:" "$version"
        printf "%-27s %s\n" "Operation Mode:" "Get IP Address"
        printf "%-27s %s\n" "Num Sources:" "$numIpToUseForGetIP (used for verification)"
        printf "%-27s %s\n" "Timeout (Seconds):" "$timeout"
        printf "%-27s %s\n" "Download Utility:" "$urlDownloadProgramForDisplay"
    fi

    # Read the source urls into $urlArray.
    Read_Source_Url_List

    if [ "$verbose" = "TRUE" ]; then
        printf "%-27s %s\n" "Source Urls Download:" "Succeeded ($urlArrayLength urls)"
    fi

    # Check if the number of source urls is fewer than the required minimum.
    if [ "$urlArrayLength" -lt "$sourceUrlsMinimum" ]; then
        Output_Error_Message "NotEnoughSourceUrls"
        exit "$ExitStatusErrorNotEnoughSourceUrls"
    fi

    # Shuffle the source urls array.
    Randomize_Url_List

    if [ "$verbose" = "TRUE" ]; then
        printf "%-27s %s\n" "Source Urls Randomizing:" "Done"
    fi

    # Array to hold the IP addresses retrieved.
    local ipList=""

    # Counter to hold how many IP addresses have so far been retrieved.
    local ipCounter="0"

    # Test error handling with 'fake' IP address.
    # 1 = has 1 IP address, 2 = has 2 IP addresses, 3 = no IP addresses.
    # urlArray[1]="https://crius.feralhosting.com/gencon/fakeip1.html"
    # urlArray[1]="https://crius.feralhosting.com/gencon/fakeip2.html"
    # urlArray[1]="https://crius.feralhosting.com/gencon/fakeip3.html"

    # Loop through the urls in $urlArray. The script will exit from within this loop if the IP
    # address has been successfully retrieved from the required number of sources and verified.

    for url in "${urlArray[@]}"; do

        if [ "$verbose" = "TRUE" ]; then
            timeStart=$(date +%s.%N);
            printf "\n%-27s %s\n" "Trying Source:" "$url"
        fi

        # Store any IP addresses in the page source of $url in $ipAddress.
        ipAddress=$(Get_Ip_From_Url "$url")
        getIpFromUrlRetVal=$?

        # Failed due to a temp file creation error.
        if [ "$getIpFromUrlRetVal" -eq "$GetIpTempFileCreationFailed" ]; then
            Output_Error_Message "TempFileCreationFailed"
            exit "$ExitStatusErrorTempFileCreationFailed"
        fi

        if [ "$verbose" = "TRUE" ]; then

            # Calculate the time taken (reduce to 3 decimal places).
            timeStop=$(date +%s.%N)
            timeTaken=$(printf "%.3F" $(echo "$timeStop - $timeStart" | bc -l))

            if [ "$getIpFromUrlRetVal" -eq "$GetIpSingleValidIP" ]; then
                ipStatusVerbose="Valid IP address: $ipAddress"

            elif [ "$getIpFromUrlRetVal" -eq "$GetIpNoValidIP" ]; then
                ipStatusVerbose="Failed: No IP address"

            elif [ "$getIpFromUrlRetVal" -eq "$GetIpMultipleValidIP" ]; then
                ipStatusVerbose="Failed: More than one IP address"

            elif [ "$getIpFromUrlRetVal" -eq "$GetIpTimedOut" ]; then
                ipStatusVerbose="Failed: Server timed out"
            fi

            printf "%-27s %s\n" "Status:" "$ipStatusVerbose"
            printf "%-27s %s\n" "Duration:" "$timeTaken seconds"
        fi

        # If a single valid IP addresses was retrieved.
        if [ "$getIpFromUrlRetVal" -eq "$GetIpSingleValidIP" ]; then

            # Add the IP address to the array, and increment the counter.
            ipList[$ipCounter]="$ipAddress"
            let "ipCounter = ipCounter + 1"

            if [ "$verbose" = "TRUE" ]; then
                printf "%-27s %s\n" "Add IP To List:" "$ipCounter of $numIpToUseForGetIP"
            fi

            # Check if all the IP addresses in the array are the same.
            Verify_IP_List "${ipList[@]}"
            verifyIpRetVal=$?

            # If the IP addresses in the array are NOT all the same then re-start.
            if [ "$verifyIpRetVal" = "$VerifyIpNotTheSame" ]; then

                if [ "$verbose" = "TRUE" ]; then
                    printf "\n%-27s %s\n" "IP List Verification:" "Failed [IP addresses differed]"
                    printf "%-27s %s\n" "Status:" "Restart using different sources"
                fi

                # Reset the array and counter variables.
                unset ipList
                ipCounter="0"
            fi

            # If the array now contains the required number of IP addresses to use for verification
            # then output the IP address and exit. Note: The if statement below will only evaluate
            # to true if the IP addresses in the array are all the same, if they weren't then
            # $ipCounter would have been set to 0 in the conditional above.
            if [ "$ipCounter" -eq "$numIpToUseForGetIP" ]; then

                if [ "$verbose" = "TRUE" ]; then
                    printf "\n%-27s %s" "IP List Verification:" "Succeeded "
                    printf "%s\n" "[$ipCounter identical IP addresses]"
                    printf "\n%-27s %s\n" "IPv4 address:" "$ipAddress"
                else
                    if [ "$bareOutput" = "TRUE" ]; then
                        printf "%s\n" "$ipAddress"
                    else
                        printf "%s\n" "IPv4 address: $ipAddress"
                    fi
                fi

                # The exit point of the script in getip mode.
                exit "$ExitStatusSuccess"
            fi
        fi

    done  # End of loop through $urlArray loop.

    # The exit point of the script in getip mode if the script failed to supply a valid IP address
    # from the required number of sources.
    Output_Error_Message "FailedToGetIPAddress"
    exit "$ExitStatusErrorFailedToGetIPAddress"
}


# Function which controls testing a web page to see if suitable for inclusion in the source list.
Handle_Test_Url_Mode()
{
    timeStart=$(date +%s.%N)

    # Store any IP addresses in the page source of $url in $ipAddress.
    ipAddress=$(Get_Ip_From_Url "$testUrlAddress")
    getIpFromUrlRetVal=$?

    # Failed due to temp file creation error.
    if [ "$getIpFromUrlRetVal" -eq "$GetIpTempFileCreationFailed" ]; then
        Output_Error_Message "TempFileCreationFailed"
        exit "$ExitStatusErrorTempFileCreationFailed"
    fi

    timeStop=$(date +%s.%N)
    timeTaken=$(printf "%.3F" $(echo "$timeStop - $timeStart" | bc -l))

    # 'Pretty print' the test results.

    printf "\n%-20s %s\n" "Script Version:" "$version"
    printf "%-20s %s\n" "Operation Mode:" "Test Url"
    printf "%-20s %s\n" "Download Utility:" "$urlDownloadProgramForDisplay"
    printf "%-20s %s\n" "Url:" "$testUrlAddress"
    printf "%-20s %s\n" "Duration:" "$timeTaken seconds"

    if [ "$getIpFromUrlRetVal" -eq "$GetIpSingleValidIP" ]; then
        printf "%-20s %s\n" "Outcome:" "Url provided a single IP address - $ipAddress"
        printf "%-20s %s\n" "Status:" "Success"
        printf "%-20s %s\n" "Conclusion:" "Url is suitable for using as a source."

    elif [ "$getIpFromUrlRetVal" -eq "$GetIpMultipleValidIP" ]; then
        printf "%-20s %s\n" "Outcome:" "Url provided more than one IP address."
        ipAddressSSV=$(echo "$ipAddress" | tr '\n' ' ' | sed "s/ /, /g" | sed "s/, $//g")
        printf "%-20s %s\n" "IP Addresses:" "$ipAddressSSV"
        printf "%-20s %s\n" "Status:" "Failure"
        printf "%-20s %s\n" "Conclusion:" "Url is NOT suitable for using as a source."

    elif [ "$getIpFromUrlRetVal" -eq "$GetIpNoValidIP" ]; then
        printf "%-20s %s\n" "Outcome:" "Url provided no IP addresses."
        printf "%-20s %s\n" "Status:" "Failure"
        printf "%-20s %s\n" "Conclusion:" "Url is NOT suitable for using as a source."

    elif [ "$getIpFromUrlRetVal" -eq "$GetIpTimedOut" ]; then
        printf "%-20s %s\n" "Outcome:" "Server timed out (timeout set at: $timeout seconds)."
        printf "%-20s %s\n" "Status:" "Failure"
        printf "%-20s %s\n" "Conclusion:" "Url is NOT suitable for using as a source unless the"
        printf "%-20s %s\n" "" "timeout was set very low or its timing out is unusual."
    fi

    # The exit point of the script in test url mode.
    exit "$ExitStatusSuccess"
}


# Function which controls checking if the web pages in the source list are working or not.
Handle_Check_Mode()
{
    printf "\n%-24s %s\n" "Script Version:" "$version"
    printf "%-24s %s\n" "Operation Mode:" "Check Source Urls"
    printf "%-24s %s\n" "Timeout (Seconds):" "$timeout"
    printf "%-24s %s\n" "Download Utility:" "$urlDownloadProgramForDisplay"

    # Read the source urls into $urlArray.
    Read_Source_Url_List

    printf "%-24s %s\n\n" "Source Urls Download:" "Succeeded ($urlArrayLength Urls)"

    # Table header.
    printf "%s\n" "------------------------------------------------------------------------------"
    printf "%-23s %-40s %s\n" "Seconds" "Url" "IP/Status"
    printf "%s\n" "------------------------------------------------------------------------------"

    # Loop through the urls in $urlArray providing information about the status of each one.

    for url in "${urlArray[@]}"; do

        timeStart=$(date +%s.%N);

        # Store any IP addresses in the page source of $url in $ipAddress.
        ipAddress=$(Get_Ip_From_Url "$url")
        getIpFromUrlRetVal=$?

        # Failed due to temp file creation error.
        if [ "$getIpFromUrlRetVal" -eq "$GetIpTempFileCreationFailed" ]; then
            Output_Error_Message "TempFileCreationFailed"
            exit "$ExitStatusErrorTempFileCreationFailed"
        fi

        # Set $ipStatus according to Get_Ip_From_Url()'s return value.

        if [ "$getIpFromUrlRetVal" -eq "$GetIpSingleValidIP" ]; then
            # Add_To_Stats() matches "VALID_IP", so if changing change there too.
            ipStatus="VALID_IP"

        elif [ "$getIpFromUrlRetVal" -eq "$GetIpNoValidIP" ]; then
            ipStatus="NO IP ADDRESS"

        elif [ "$getIpFromUrlRetVal" -eq "$GetIpMultipleValidIP" ]; then
            ipStatus="MULTIPLE IP"

        elif [ "$getIpFromUrlRetVal" -eq "$GetIpTimedOut" ]; then
            ipStatus="URL TIMED OUT"
        fi

        # Calculate the time taken (reduce to 3 decimal places).
        timeStop=$(date +%s.%N)
        timeTaken=$(printf "%.3F" $(echo "$timeStop - $timeStart" | bc -l))

        # Neatly display the duration, source url, and the IP address or failure status.

        # Truncate the $url if its length will muck up the table columns.
        urlLength=${#url}
        if [ "$urlLength" -gt "52" ]; then
            truncateUrl=${url:0:48}
            url="$truncateUrl..."
        fi

        if [ "$getIpFromUrlRetVal" -eq "$GetIpSingleValidIP" ]; then
            printf "%-8s %-53s %s\n" "$timeTaken" "$url" "$ipAddress"
        else
            printf "%-8s %-53s %s\n" "$timeTaken" "$url" "$ipStatus"
        fi

        # Add info. to the stored statistics for displaying at the end.
        Add_To_Stats "$ipAddress" "$ipStatus" "$timeTaken"

    done  # End of loop through $urlArray loop.

    # Display the stats info.
    Display_Stats

    # The exit point of the script in check mode.
    exit "$ExitStatusSuccess"
}


#
# Process The Command Line.
#


# Before processing the arguments with getopts, check for long options:

# Check if the first arg is "--help", if so display help and exit (-h is handled by getopts).
if [ "$1" = "--help" -o "$1" = "-?" ]; then
    Display_Usage_Message
    exit "$ExitStatusSuccess"

# Check if the first arg is "--version", etc., if so display version number and exit.
elif [ "$1" = "--version" -o "$1" = "-version" -o "$1" = "-ver" ]; then
    echo "getip v. $version"
    exit "$ExitStatusSuccess"
fi

# Use getopts to process the command line arguments.
while getopts ":gcu:bvhn:t:d:" option; do

    case $option in

        g)
            # -g has been used, set operation mode to GETIP.
            operationMode="GETIP"
            let "userSetModesCounter = userSetModesCounter + 1"
            ;;

        c)
            # -c has been used, set operation mode to CHECK.
            operationMode="CHECK"
            let "userSetModesCounter = userSetModesCounter + 1"
            ;;

        u)
            # -u url has been used, set operation mode to TESTURL and set the url address.
            operationMode="TESTURL"
            testUrlAddress="$OPTARG"
            let "userSetModesCounter = userSetModesCounter + 1"

            # Check if $testUrlAddress is an url by seeing if the first 4 chars are 'http'.
            urlFirst4Chars=${testUrlAddress:0:4}
            urlFirst4CharsLowerCase=$(echo "$urlFirst4Chars" | tr '[:upper:]' '[:lower:]')

            if [ "$urlFirst4CharsLowerCase" != "http" ]; then
                Output_Error_Message "ArgInvalid" "-u"
                exit "$ExitStatusErrorUrlArgInvalid"
            fi
            ;;

        b)
            # -b has been used, turn on bare output.
            bareOutput="TRUE"
            ;;

        v)
            # -v has been used, turn on verbose.
            verbose="TRUE"
            ;;

        h)
            # -h has been used, display help and then exit.
            Display_Usage_Message
            exit "$ExitStatusSuccess"
            ;;

        n)
            # -n num has been used, set the number of sources to use and flag variable.
            numIpToUseForGetIP="$OPTARG"
            userSetNumIpToUseForGetIP="TRUE"

            # Use sed to check that $numIpToUseForGetIP is a single digit >=2 and <=5.
            numMin="2"
            numMax="5"

            sedExpIsNumInRange="s/^[$numMin-$numMax]\{1\}$/SINGLE_DIGIT_IN_RANGE/g"
            isNumInRange=$(echo "$numIpToUseForGetIP" | sed "$sedExpIsNumInRange")

            # A single digit in range has not been entered.
            if [ "$isNumInRange" != "SINGLE_DIGIT_IN_RANGE" ]; then
                Output_Error_Message "ArgInvalid" "-n"
                exit "$ExitStatusErrorNumSourcesArgInvalid"
            fi
            ;;

        t)
            # -t seconds has been used, set the timeout flag and arg variables.
            timeoutSecondsArg="$OPTARG"
            userSetTimeout="TRUE"

            # Check that $timeoutSecondsArg is a number, int or real. This is a Bash hack to use
            # awk to check whether a variable is any kind of number (int or real).
            awkIsNum='{ if ($1 + 0 == $1) print "Num"; else print "NotNum" }'
            awkIsNumRetVal=$(echo "$timeoutSecondsArg" | awk "$awkIsNum")

            if [ "$awkIsNumRetVal" = "NotNum" ]; then
                Output_Error_Message "ArgInvalid" "-t"
                exit "$ExitStatusErrorTimeoutArgInvalid"
            fi

            # Use bc to check that $timeoutSecondsArg is a number in range, >=0.2 and <=30.
            # The awk check has to be done first as bc doesn't like being given a non-number.

            timeoutMin="0.2"
            timeoutMax="30"

            bcExpIsNumInRange="if ($timeoutSecondsArg < $timeoutMin || \
                                   $timeoutSecondsArg > $timeoutMax) 1 else 0"
            bcExpIsNumInRangeRetVal=$(echo "$bcExpIsNumInRange" | bc -l)

            # A positive number in range has not been entered.
            if [ "$bcExpIsNumInRangeRetVal" = "1" ]; then
                Output_Error_Message "ArgInvalid" "-t"
                exit "$ExitStatusErrorTimeoutArgInvalid"
            fi
            ;;

        d)
            # -d has been used to set the download program, set which program to use.

            userSetUrlDownloadProgramLC=$(echo "$OPTARG" | tr '[:upper:]' '[:lower:]')

            if [ "$userSetUrlDownloadProgramLC" = "wget" ]; then
                userSetUrlDownloadProgram="WGET"

            elif [ "$userSetUrlDownloadProgramLC" = "curl" ]; then
                userSetUrlDownloadProgram="CURL"

            else
                Output_Error_Message "ArgInvalid" "-d"
                exit "$ExitStatusErrorUrlDownloadProgramArgInvalid"
            fi
            ;;

        \?)
            # User entered an invalid option, e.g. '-x'. Note: Invalid args with no '-' prefix,
            # are handled immediately after this while loop.
            Output_Error_Message "OptionInvalid"
            exit "$ExitStatusErrorOptionInvalid"
            ;;

        :)
            # User omitted the required additional arg of an option (e.g. -t <BLANK>).
            Output_Error_Message "ArgMissing" "$OPTARG"
            exit "$ExitStatusErrorArgMissing"
            ;;
    esac
done


# getopts stops processing args if it encounters an arg without a '-' prefix (unless it is an
# $OPTARG in which case processing continues). Check if any invalid args have been entered by
# working out how many args getopts has actually processed, shifting them off, and if more
# than 0 args remain then an invalid arg must have been entered.

let "numArgsProcessedByGetopts = OPTIND - 1"
shift "$numArgsProcessedByGetopts"
numArgsRemaining="$#"

if [ "$numArgsRemaining" -gt "0" ]; then
    Output_Error_Message "OptionInvalid"
    exit "$ExitStatusErrorOptionInvalid"
fi

# If the user set more than 1 mode on the command line, display error and exit.
if [ "$userSetModesCounter" -gt "1" ]; then
    Output_Error_Message "UserSetMoreThanOneMode"
    exit "$ExitStatusErrorUserSetMoreThanOneMode"
fi

# Set the appropriate timeout.

# If the user set the timeout use that otherwise use the default.
if [ "$userSetTimeout" = "TRUE" ]; then
    timeout="$timeoutSecondsArg"
else
    if [ "$operationMode" = "GETIP" ]; then
        timeout="$timeoutGetIPMode"
    elif [ "$operationMode" = "CHECK" ]; then
        timeout="$timeoutCheckMode"
    elif [ "$operationMode" = "TESTURL" ]; then
        timeout="$timeoutTestUrlMode"
    fi
fi

# If the user has set both verbose and bare output, display error and exit.
if [ "$verbose" = "TRUE" -a "$bareOutput" = "TRUE" ]; then
    Output_Error_Message "UserSetVerboseAndBare"
    exit "$ExitStatusErrorUserSetVerboseAndBare"
fi

# Either wget or curl can be used to download the source urls.
# $urlDownloadProgram will hold which to use, either: 'WGET' or 'CURL'.

# Check whether wget and curl are installed, at least one is required.
hash wget > /dev/null 2>&1
isWgetInstalled=$?
hash curl > /dev/null 2>&1
isCurlInstalled=$?

# Decide whether to use wget or curl for web page url downloading.

# If the user has not set which one to use on the command line.
if [ "$userSetUrlDownloadProgram" = "FALSE" ]; then

    # If both wget and curl are installed, use the default.
    if [ "$isWgetInstalled" -eq "0" -a "$isCurlInstalled" -eq "0" ]; then
        urlDownloadProgram="$urlDefaultDownloadProgram"

    # If only wget is installed, use that.
    elif [ "$isWgetInstalled" -eq "0" -a "$isCurlInstalled" -ne "0" ]; then
        urlDownloadProgram="WGET"

    # If only curl is installed, use that.
    elif [ "$isCurlInstalled" -eq "0" -a "$isWgetInstalled" -ne "0" ]; then
        urlDownloadProgram="CURL"

    # If neither wget nor curl are installed, display error and exit.
    else
        Output_Error_Message "WgetAndCurlNotInstalled"
        exit "$ExitStatusErrorUrlDownloadProgramNotInstalled"
    fi

# If the user has set which one to use on the command line.
else

    # If the user set wget, use that if it is installed.
    if [ "$userSetUrlDownloadProgram" = "WGET" -a "$isWgetInstalled" -eq "0" ]; then
        urlDownloadProgram="WGET"

    elif [ "$userSetUrlDownloadProgram" = "WGET" -a "$isWgetInstalled" -ne "0" ]; then
        Output_Error_Message "WgetNotInstalled"
        exit "$ExitStatusErrorUrlDownloadProgramNotInstalled"

    # If the user set curl, use that if it is installed.
    elif [ "$userSetUrlDownloadProgram" = "CURL" -a "$isCurlInstalled" -eq "0" ]; then
        urlDownloadProgram="CURL"

    elif [ "$userSetUrlDownloadProgram" = "CURL" -a "$isCurlInstalled" -ne "0" ]; then
        Output_Error_Message "CurlNotInstalled"
        exit "$ExitStatusErrorUrlDownloadProgramNotInstalled"
    fi
fi

# Set the url download program display text (just to make verbose output neater).
if [ "$urlDownloadProgram" = "WGET" ]; then
    urlDownloadProgramForDisplay="Wget"
elif [ "$urlDownloadProgram" = "CURL" ]; then
    urlDownloadProgramForDisplay="Curl"
fi

# Call the appropriate function for the operation mode, the script will exit from within these
# functions so the conditional below will never complete.

if [ "$operationMode" = "GETIP" ]; then
    Handle_Get_IP_Mode

elif [ "$operationMode" = "TESTURL" ]; then
    Handle_Test_Url_Mode

elif [ "$operationMode" = "CHECK" ]; then
    Handle_Check_Mode
fi


##
## END OF SCRIPT.
##
